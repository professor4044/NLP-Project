{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjXok+xdEiAUEVjdmnJ4Q2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/professor4044/NLP-Project/blob/main/NLPProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK : 1 : Load Python Libraries"
      ],
      "metadata": {
        "id": "jpaiPivXqMgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, json, time, random, string, urllib.request\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet as wn\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support,\n",
        "    classification_report, confusion_matrix,\n",
        "    roc_auc_score, roc_curve\n",
        ")\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "import sklearn, matplotlib\n"
      ],
      "metadata": {
        "id": "O2cLoG-nqZjX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK : 2 : Load NLTK package"
      ],
      "metadata": {
        "id": "27BPNXHfqpkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "packages = [\n",
        "    \"punkt\", \"stopwords\", \"wordnet\", \"omw-1.4\",\n",
        "    \"averaged_perceptron_tagger\", \"averaged_perceptron_tagger_eng\",\n",
        "    \"punkt_tab\"\n",
        "]\n",
        "\n",
        "for p in packages:\n",
        "    try:\n",
        "        nltk.download(p, quiet=True)\n",
        "    except Exception as e:\n",
        "        print(f\"NLTK download failed for {p}: {e}\")\n",
        "\n",
        "STOP_WORDS = set(stopwords.words(\"english\"))\n",
        "stemmer = PorterStemmer()\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "print(\"NLTK done\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89wVAWM-q20g",
        "outputId": "ee61f4aa-2ec0-4c39-e9e1-10b235e84dac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK : 3 :Load dataset"
      ],
      "metadata": {
        "id": "YIX3fDpUK74c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "dataset = load_dataset(\"csv\", data_files=\"fake.csv\", split=\"train[:10000]\")\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "print(df.head(3))\n",
        "\n",
        "print(\"Label distribution:\", Counter(df[\"type\"].tolist()))\n",
        "\n",
        "print(\"Total rows:\", len(df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDq74UWXLG60",
        "outputId": "21e676e6-abd9-4599-f1fb-4eed67c43609"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       uuid  ord_in_thread  \\\n",
            "0  6a175f46bcd24d39b3e962ad0f29936721db70db              0   \n",
            "1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b              0   \n",
            "2  c70e149fdd53de5e61c29281100b9de0ed268bc3              0   \n",
            "\n",
            "                 author                      published  \\\n",
            "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
            "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
            "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
            "\n",
            "                                               title  \\\n",
            "0  Muslims BUSTED: They Stole Millions In Gov’t B...   \n",
            "1  Re: Why Did Attorney General Loretta Lynch Ple...   \n",
            "2  BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
            "\n",
            "                                                text language  \\\n",
            "0  Print They should pay all the back all the mon...  english   \n",
            "1  Why Did Attorney General Loretta Lynch Plead T...  english   \n",
            "2  Red State : \\nFox News Sunday reported this mo...  english   \n",
            "\n",
            "                         crawled             site_url country  domain_rank  \\\n",
            "0  2016-10-27T01:49:27.168+03:00  100percentfedup.com      US      25689.0   \n",
            "1  2016-10-29T08:47:11.259+03:00  100percentfedup.com      US      25689.0   \n",
            "2  2016-10-31T01:41:49.479+02:00  100percentfedup.com      US      25689.0   \n",
            "\n",
            "                                        thread_title  spam_score  \\\n",
            "0  Muslims BUSTED: They Stole Millions In Gov’t B...         0.0   \n",
            "1  Re: Why Did Attorney General Loretta Lynch Ple...         0.0   \n",
            "2  BREAKING: Weiner Cooperating With FBI On Hilla...         0.0   \n",
            "\n",
            "                                        main_img_url  replies_count  \\\n",
            "0  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
            "1  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
            "2  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
            "\n",
            "   participants_count  likes  comments  shares  type  \n",
            "0                   1      0         0       0  bias  \n",
            "1                   1      0         0       0  bias  \n",
            "2                   1      0         0       0  bias  \n",
            "Label distribution: Counter({'bs': 8693, 'conspiracy': 430, 'hate': 246, 'bias': 243, 'satire': 146, 'state': 121, 'junksci': 102, 'fake': 19})\n",
            "Total rows: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK :4:Case folding"
      ],
      "metadata": {
        "id": "05q7SsOM6In4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "df[text_cols] = df[text_cols].apply(lambda x: x.astype(str).str.lower())\n",
        "\n",
        "print(df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3esNPIY6Q1v",
        "outputId": "2b12df79-3d72-4db6-98aa-ba719dd4424e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       uuid  ord_in_thread  \\\n",
            "0  6a175f46bcd24d39b3e962ad0f29936721db70db              0   \n",
            "1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b              0   \n",
            "2  c70e149fdd53de5e61c29281100b9de0ed268bc3              0   \n",
            "\n",
            "                 author                      published  \\\n",
            "0     barracuda brigade  2016-10-26t21:41:00.000+03:00   \n",
            "1  reasoning with facts  2016-10-29t08:47:11.259+03:00   \n",
            "2     barracuda brigade  2016-10-31t01:41:49.479+02:00   \n",
            "\n",
            "                                               title  \\\n",
            "0  muslims busted: they stole millions in gov’t b...   \n",
            "1  re: why did attorney general loretta lynch ple...   \n",
            "2  breaking: weiner cooperating with fbi on hilla...   \n",
            "\n",
            "                                                text language  \\\n",
            "0  print they should pay all the back all the mon...  english   \n",
            "1  why did attorney general loretta lynch plead t...  english   \n",
            "2  red state : \\nfox news sunday reported this mo...  english   \n",
            "\n",
            "                         crawled             site_url country  domain_rank  \\\n",
            "0  2016-10-27t01:49:27.168+03:00  100percentfedup.com      us      25689.0   \n",
            "1  2016-10-29t08:47:11.259+03:00  100percentfedup.com      us      25689.0   \n",
            "2  2016-10-31t01:41:49.479+02:00  100percentfedup.com      us      25689.0   \n",
            "\n",
            "                                        thread_title  spam_score  \\\n",
            "0  muslims busted: they stole millions in gov’t b...         0.0   \n",
            "1  re: why did attorney general loretta lynch ple...         0.0   \n",
            "2  breaking: weiner cooperating with fbi on hilla...         0.0   \n",
            "\n",
            "                                        main_img_url  replies_count  \\\n",
            "0  http://bb4sp.com/wp-content/uploads/2016/10/fu...              0   \n",
            "1  http://bb4sp.com/wp-content/uploads/2016/10/fu...              0   \n",
            "2  http://bb4sp.com/wp-content/uploads/2016/10/fu...              0   \n",
            "\n",
            "   participants_count  likes  comments  shares  type  \n",
            "0                   1      0         0       0  bias  \n",
            "1                   1      0         0       0  bias  \n",
            "2                   1      0         0       0  bias  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK:5:Punctuation removal"
      ],
      "metadata": {
        "id": "jaCGeIJgNATj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ১. টেক্সট কলামগুলো খুঁজে বের করা\n",
        "text_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# ২. Regex দিয়ে Punctuation রিমুভ করা\n",
        "# r'[^\\w\\s]' প্যাটার্নটির মানে: Word এবং Space ছাড়া সব রিমুভ করো\n",
        "for col in text_cols:\n",
        "    df[col] = df[col].astype(str).str.replace(r'[^\\w\\s]', '', regex=True)\n",
        "\n",
        "# ৩. আউটপুট দেখা\n",
        "print(df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwxyuUjANJnR",
        "outputId": "10d442d4-096b-4356-d176-6ba546a813e7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       uuid  ord_in_thread  \\\n",
            "0  6a175f46bcd24d39b3e962ad0f29936721db70db              0   \n",
            "1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b              0   \n",
            "2  c70e149fdd53de5e61c29281100b9de0ed268bc3              0   \n",
            "\n",
            "                 author               published  \\\n",
            "0     barracuda brigade  20161026t2141000000300   \n",
            "1  reasoning with facts  20161029t0847112590300   \n",
            "2     barracuda brigade  20161031t0141494790200   \n",
            "\n",
            "                                               title  \\\n",
            "0  muslims busted they stole millions in govt ben...   \n",
            "1  re why did attorney general loretta lynch plea...   \n",
            "2  breaking weiner cooperating with fbi on hillar...   \n",
            "\n",
            "                                                text language  \\\n",
            "0  print they should pay all the back all the mon...  english   \n",
            "1  why did attorney general loretta lynch plead t...  english   \n",
            "2  red state  \\nfox news sunday reported this mor...  english   \n",
            "\n",
            "                  crawled            site_url country  domain_rank  \\\n",
            "0  20161027t0149271680300  100percentfedupcom      us      25689.0   \n",
            "1  20161029t0847112590300  100percentfedupcom      us      25689.0   \n",
            "2  20161031t0141494790200  100percentfedupcom      us      25689.0   \n",
            "\n",
            "                                        thread_title  spam_score  \\\n",
            "0  muslims busted they stole millions in govt ben...         0.0   \n",
            "1  re why did attorney general loretta lynch plea...         0.0   \n",
            "2  breaking weiner cooperating with fbi on hillar...         0.0   \n",
            "\n",
            "                                        main_img_url  replies_count  \\\n",
            "0  httpbb4spcomwpcontentuploads201610fullscreenca...              0   \n",
            "1  httpbb4spcomwpcontentuploads201610fullscreenca...              0   \n",
            "2  httpbb4spcomwpcontentuploads201610fullscreenca...              0   \n",
            "\n",
            "   participants_count  likes  comments  shares  type  \n",
            "0                   1      0         0       0  bias  \n",
            "1                   1      0         0       0  bias  \n",
            "2                   1      0         0       0  bias  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK:6:Tokenization"
      ],
      "metadata": {
        "id": "a_yark5bPjmR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BykpCWlLPwj-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}