{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMO2OACwznr+FBaeX2ypIVE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/professor4044/NLP-Project/blob/main/NLPProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK : 1 : Load Python Libraries"
      ],
      "metadata": {
        "id": "jpaiPivXqMgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, json, time, random, string, urllib.request\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet as wn\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support,\n",
        "    classification_report, confusion_matrix,\n",
        "    roc_auc_score, roc_curve\n",
        ")\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "import sklearn, matplotlib\n"
      ],
      "metadata": {
        "id": "O2cLoG-nqZjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK : 2 : Load NLTK package"
      ],
      "metadata": {
        "id": "27BPNXHfqpkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "packages = [\n",
        "    \"punkt\", \"stopwords\", \"wordnet\", \"omw-1.4\",\n",
        "    \"averaged_perceptron_tagger\", \"averaged_perceptron_tagger_eng\",\n",
        "    \"punkt_tab\"\n",
        "]\n",
        "\n",
        "for p in packages:\n",
        "    try:\n",
        "        nltk.download(p, quiet=True)\n",
        "    except Exception as e:\n",
        "        print(f\"NLTK download failed for {p}: {e}\")\n",
        "\n",
        "STOP_WORDS = set(stopwords.words(\"english\"))\n",
        "stemmer = PorterStemmer()\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "print(\"NLTK done\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89wVAWM-q20g",
        "outputId": "406e0286-9040-4ed0-85df-c41cb6584730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK : 3 :Load dataset"
      ],
      "metadata": {
        "id": "YIX3fDpUK74c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "dataset = load_dataset(\"csv\", data_files=\"fake.csv\", split=\"train[:10000]\")\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "print(df.head(3))\n",
        "\n",
        "print(\"Label distribution:\", Counter(df[\"type\"].tolist()))\n",
        "\n",
        "print(\"Total rows:\", len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDq74UWXLG60",
        "outputId": "7d24802c-c1df-4db6-c103-b60cb2b2c2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       uuid  ord_in_thread  \\\n",
            "0  6a175f46bcd24d39b3e962ad0f29936721db70db              0   \n",
            "1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b              0   \n",
            "2  c70e149fdd53de5e61c29281100b9de0ed268bc3              0   \n",
            "\n",
            "                 author                      published  \\\n",
            "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
            "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
            "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
            "\n",
            "                                               title  \\\n",
            "0  Muslims BUSTED: They Stole Millions In Gov’t B...   \n",
            "1  Re: Why Did Attorney General Loretta Lynch Ple...   \n",
            "2  BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
            "\n",
            "                                                text language  \\\n",
            "0  Print They should pay all the back all the mon...  english   \n",
            "1  Why Did Attorney General Loretta Lynch Plead T...  english   \n",
            "2  Red State : \\nFox News Sunday reported this mo...  english   \n",
            "\n",
            "                         crawled             site_url country  domain_rank  \\\n",
            "0  2016-10-27T01:49:27.168+03:00  100percentfedup.com      US      25689.0   \n",
            "1  2016-10-29T08:47:11.259+03:00  100percentfedup.com      US      25689.0   \n",
            "2  2016-10-31T01:41:49.479+02:00  100percentfedup.com      US      25689.0   \n",
            "\n",
            "                                        thread_title  spam_score  \\\n",
            "0  Muslims BUSTED: They Stole Millions In Gov’t B...         0.0   \n",
            "1  Re: Why Did Attorney General Loretta Lynch Ple...         0.0   \n",
            "2  BREAKING: Weiner Cooperating With FBI On Hilla...         0.0   \n",
            "\n",
            "                                        main_img_url  replies_count  \\\n",
            "0  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
            "1  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
            "2  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
            "\n",
            "   participants_count  likes  comments  shares  type  \n",
            "0                   1      0         0       0  bias  \n",
            "1                   1      0         0       0  bias  \n",
            "2                   1      0         0       0  bias  \n",
            "Label distribution: Counter({'bs': 8693, 'conspiracy': 430, 'hate': 246, 'bias': 243, 'satire': 146, 'state': 121, 'junksci': 102, 'fake': 19})\n",
            "Total rows: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK : 4 :Data Cleaning"
      ],
      "metadata": {
        "id": "MeiMJXmWXIQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before cleaning nulls:\", df.shape)\n",
        "\n",
        "df = df.dropna(subset=['title', 'text', 'type'])\n",
        "\n",
        "df = df[['title', 'text', 'type']]\n",
        "\n",
        "print(\"After cleaning nulls:\", df.shape)\n",
        "\n",
        "print(df.head(3))\n",
        "\n",
        "\n",
        "df['title'] = df['title'].fillna('')\n",
        "df['text'] = df['text'].fillna('')\n",
        "\n",
        "df['text'] = df['title'] + \" \" + df['text']\n",
        "\n",
        "df = df[['text', 'type']]\n",
        "\n",
        "print(df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMmVUp_FadJW",
        "outputId": "dca9c212-d2c8-4463-8592-e4bcede51088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before cleaning nulls: (10000, 20)\n",
            "After cleaning nulls: (9550, 3)\n",
            "                                               title  \\\n",
            "0  Muslims BUSTED: They Stole Millions In Gov’t B...   \n",
            "1  Re: Why Did Attorney General Loretta Lynch Ple...   \n",
            "2  BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
            "\n",
            "                                                text  type  \n",
            "0  Print They should pay all the back all the mon...  bias  \n",
            "1  Why Did Attorney General Loretta Lynch Plead T...  bias  \n",
            "2  Red State : \\nFox News Sunday reported this mo...  bias  \n",
            "                                                text  type\n",
            "0  Muslims BUSTED: They Stole Millions In Gov’t B...  bias\n",
            "1  Re: Why Did Attorney General Loretta Lynch Ple...  bias\n",
            "2  BREAKING: Weiner Cooperating With FBI On Hilla...  bias\n"
          ]
        }
      ]
    }
  ]
}