{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMozb2pJW0qlsGkCNptewYy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "69479de4c2374393b48595e47d3933fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27f9746fc2dd4252a6ac402364794911",
              "IPY_MODEL_c6f64445cf3142578c2112b9b9ce018d",
              "IPY_MODEL_a7bd6d1aa5894549b8bd1d99e1a1aa67"
            ],
            "layout": "IPY_MODEL_b182016a727649619afe45649bb47490"
          }
        },
        "27f9746fc2dd4252a6ac402364794911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff8dea8752b4caa8a95e574052f9128",
            "placeholder": "​",
            "style": "IPY_MODEL_c8dd005859014cafb917ec93bba18344",
            "value": "Generating train split: "
          }
        },
        "c6f64445cf3142578c2112b9b9ce018d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aaafbeafddb467db69398c322a89c0a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca208d281e074f94a17f3b02c4588dba",
            "value": 1
          }
        },
        "a7bd6d1aa5894549b8bd1d99e1a1aa67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86389f44dc5547c2bd3d65a8b4bf4a92",
            "placeholder": "​",
            "style": "IPY_MODEL_85cb3c32d11f4b7c9142a7248020eda4",
            "value": " 12999/0 [00:01&lt;00:00, 7981.28 examples/s]"
          }
        },
        "b182016a727649619afe45649bb47490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ff8dea8752b4caa8a95e574052f9128": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8dd005859014cafb917ec93bba18344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0aaafbeafddb467db69398c322a89c0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ca208d281e074f94a17f3b02c4588dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86389f44dc5547c2bd3d65a8b4bf4a92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85cb3c32d11f4b7c9142a7248020eda4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/professor4044/NLP-Project/blob/main/NLPProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK : 1 : Load Python Libraries"
      ],
      "metadata": {
        "id": "jpaiPivXqMgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, json, time, random, string, urllib.request\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet as wn\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support,\n",
        "    classification_report, confusion_matrix,\n",
        "    roc_auc_score, roc_curve\n",
        ")\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "import sklearn, matplotlib\n"
      ],
      "metadata": {
        "id": "O2cLoG-nqZjX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK : 2 : Load NLTK package"
      ],
      "metadata": {
        "id": "27BPNXHfqpkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "packages = [\n",
        "    \"punkt\", \"stopwords\", \"wordnet\", \"omw-1.4\",\n",
        "    \"averaged_perceptron_tagger\", \"averaged_perceptron_tagger_eng\",\n",
        "    \"punkt_tab\"\n",
        "]\n",
        "\n",
        "for p in packages:\n",
        "    try:\n",
        "        nltk.download(p, quiet=True)\n",
        "    except Exception as e:\n",
        "        print(f\"NLTK download failed for {p}: {e}\")\n",
        "\n",
        "STOP_WORDS = set(stopwords.words(\"english\"))\n",
        "stemmer = PorterStemmer()\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "print(\"NLTK done\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89wVAWM-q20g",
        "outputId": "821b8d67-7494-4381-f697-accc8f3ddb96"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK : 3 :Load dataset"
      ],
      "metadata": {
        "id": "YIX3fDpUK74c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "dataset = load_dataset(\"csv\", data_files=\"fake.csv\", split=\"train[:10000]\")\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "print(df.head(3))\n",
        "\n",
        "print(\"Label distribution:\", Counter(df[\"type\"].tolist()))\n",
        "\n",
        "print(\"Total rows:\", len(df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781,
          "referenced_widgets": [
            "69479de4c2374393b48595e47d3933fc",
            "27f9746fc2dd4252a6ac402364794911",
            "c6f64445cf3142578c2112b9b9ce018d",
            "a7bd6d1aa5894549b8bd1d99e1a1aa67",
            "b182016a727649619afe45649bb47490",
            "7ff8dea8752b4caa8a95e574052f9128",
            "c8dd005859014cafb917ec93bba18344",
            "0aaafbeafddb467db69398c322a89c0a",
            "ca208d281e074f94a17f3b02c4588dba",
            "86389f44dc5547c2bd3d65a8b4bf4a92",
            "85cb3c32d11f4b7c9142a7248020eda4"
          ]
        },
        "id": "nDq74UWXLG60",
        "outputId": "22df6deb-a3a9-4e0f-8895-071fdb0d6301"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69479de4c2374393b48595e47d3933fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       uuid  ord_in_thread  \\\n",
            "0  6a175f46bcd24d39b3e962ad0f29936721db70db              0   \n",
            "1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b              0   \n",
            "2  c70e149fdd53de5e61c29281100b9de0ed268bc3              0   \n",
            "\n",
            "                 author                      published  \\\n",
            "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
            "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
            "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
            "\n",
            "                                               title  \\\n",
            "0  Muslims BUSTED: They Stole Millions In Gov’t B...   \n",
            "1  Re: Why Did Attorney General Loretta Lynch Ple...   \n",
            "2  BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
            "\n",
            "                                                text language  \\\n",
            "0  Print They should pay all the back all the mon...  english   \n",
            "1  Why Did Attorney General Loretta Lynch Plead T...  english   \n",
            "2  Red State : \\nFox News Sunday reported this mo...  english   \n",
            "\n",
            "                         crawled             site_url country  domain_rank  \\\n",
            "0  2016-10-27T01:49:27.168+03:00  100percentfedup.com      US      25689.0   \n",
            "1  2016-10-29T08:47:11.259+03:00  100percentfedup.com      US      25689.0   \n",
            "2  2016-10-31T01:41:49.479+02:00  100percentfedup.com      US      25689.0   \n",
            "\n",
            "                                        thread_title  spam_score  \\\n",
            "0  Muslims BUSTED: They Stole Millions In Gov’t B...         0.0   \n",
            "1  Re: Why Did Attorney General Loretta Lynch Ple...         0.0   \n",
            "2  BREAKING: Weiner Cooperating With FBI On Hilla...         0.0   \n",
            "\n",
            "                                        main_img_url  replies_count  \\\n",
            "0  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
            "1  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
            "2  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
            "\n",
            "   participants_count  likes  comments  shares  type  \n",
            "0                   1      0         0       0  bias  \n",
            "1                   1      0         0       0  bias  \n",
            "2                   1      0         0       0  bias  \n",
            "Label distribution: Counter({'bs': 8693, 'conspiracy': 430, 'hate': 246, 'bias': 243, 'satire': 146, 'state': 121, 'junksci': 102, 'fake': 19})\n",
            "Total rows: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK:4:Tokenization"
      ],
      "metadata": {
        "id": "a_yark5bPjmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# ১. ফাংশন ডিফাইন করা (ছবির স্টাইলে)\n",
        "def tokenize(column_data):\n",
        "    return [word_tokenize(str(t)) for t in column_data]\n",
        "\n",
        "# ২. শুধুমাত্র 'text' কলাম টোকেনাইজ করা\n",
        "tokenized_text = tokenize(df['text'])\n",
        "\n",
        "# ৩. আউটপুট দেখা (প্রথম নিউজের প্রথম ৩০টি টোকেন)\n",
        "print(tokenized_text[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BykpCWlLPwj-",
        "outputId": "e5ee5f43-0d75-4d1c-900e-34654777ba16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Print', 'They', 'should', 'pay', 'all', 'the', 'back', 'all', 'the', 'money', 'plus', 'interest', '.', 'The', 'entire', 'family', 'and', 'everyone', 'who', 'came', 'in', 'with', 'them', 'need', 'to', 'be', 'deported', 'asap', '.', 'Why', 'did', 'it', 'take', 'two', 'years', 'to', 'bust', 'them', '?', 'Here', 'we', 'go', 'again', '…another', 'group', 'stealing', 'from', 'the', 'government', 'and']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK:5:Case folding"
      ],
      "metadata": {
        "id": "NyXL22AWfvfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# ১. শুধু 'text' কলামটি টোকেনাইজ করে একটি লিস্টে রাখা\n",
        "tokenized_text = [word_tokenize(str(news)) for news in df['text']]\n",
        "\n",
        "# ২. আউটপুট দেখা (ছবির স্টাইলে - প্রথম খবরের প্রথম ৩০টি শব্দ)\n",
        "print(tokenized_text[0][:30])"
      ],
      "metadata": {
        "id": "QmZpRAQCf3Ts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be3ab22-70bd-401b-fba9-50a2557fca00"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Print', 'They', 'should', 'pay', 'all', 'the', 'back', 'all', 'the', 'money', 'plus', 'interest', '.', 'The', 'entire', 'family', 'and', 'everyone', 'who', 'came', 'in', 'with', 'them', 'need', 'to', 'be', 'deported', 'asap', '.', 'Why']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK:6:Punctuation Removal"
      ],
      "metadata": {
        "id": "vbg9VZlTnA6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# ১. ফাংশন যা একবারে Punctuation এবং Special Character রিমুভ করবে\n",
        "def clean_tokens(doc_tokens):\n",
        "    clean_doc = []\n",
        "    for token in doc_tokens:\n",
        "        # শুধু a-z, A-Z এবং 0-9 রাখা হবে।\n",
        "        # এর মানে Punctuation এবং Special Char সব অটোমেটিক মুছে যাবে।\n",
        "        new_token = re.sub(r'[^a-zA-Z0-9]', '', token)\n",
        "\n",
        "        # মুছতে মুছতে যদি শব্দটি ফাঁকা না হয়ে যায়, তবেই লিস্টে রাখা হবে\n",
        "        if new_token != '':\n",
        "            clean_doc.append(new_token)\n",
        "    return clean_doc\n",
        "\n",
        "# ২. আপনার টোকেনাইজড টেক্সটের ওপর এই ফাংশনটি চালানো\n",
        "# (মনে রাখবেন: 'tokenized_text' হলো আপনার আগের ধাপে পাওয়া টোকেন লিস্ট)\n",
        "final_cleaned_text = [clean_tokens(tokens) for tokens in tokenized_text]\n",
        "\n",
        "# ৩. আউটপুট দেখা (প্রথম খবরের প্রথম ৩০টি ক্লিন টোকেন)\n",
        "print(final_cleaned_text[0][:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BgLPXYknJ-w",
        "outputId": "d1fe5ba4-7f04-4a05-850f-6d8e4378e856"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Print', 'They', 'should', 'pay', 'all', 'the', 'back', 'all', 'the', 'money', 'plus', 'interest', 'The', 'entire', 'family', 'and', 'everyone', 'who', 'came', 'in', 'with', 'them', 'need', 'to', 'be', 'deported', 'asap', 'Why', 'did', 'it']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK:7:Stop word removal"
      ],
      "metadata": {
        "id": "KkfAdHSFoRrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# ১. স্টপওয়ার্ডস লোড করা\n",
        "#nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# ২. ফাংশন তৈরি\n",
        "def remove_stopwords(tokens_list):\n",
        "    # স্টপ ওয়ার্ড লিস্টে নেই এমন শব্দগুলোই শুধু রাখা হবে\n",
        "    return [word for word in tokens_list if word not in stop_words]\n",
        "\n",
        "# ৩. আপনার ক্লিন করা টেক্সটের ওপর এটি অ্যাপ্লাই করা\n",
        "# (মনে রাখবেন: 'final_cleaned_text' হলো আপনার আগের ধাপের স্পেশাল ক্যারেক্টার রিমুভ করা লিস্ট)\n",
        "text_without_stopwords = [remove_stopwords(tokens) for tokens in final_cleaned_text]\n",
        "\n",
        "# ৪. আউটপুট দেখা (সরাসরি লিস্ট)\n",
        "print(text_without_stopwords[0][:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DxGeZ_BqGEX",
        "outputId": "546d3c7d-a4cb-4450-a71c-9c57a853140e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Print', 'They', 'pay', 'back', 'money', 'plus', 'interest', 'The', 'entire', 'family', 'everyone', 'came', 'need', 'deported', 'asap', 'Why', 'take', 'two', 'years', 'bust', 'Here', 'go', 'another', 'group', 'stealing', 'government', 'taxpayers', 'A', 'group', 'Somalis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK:8:Lemmatization"
      ],
      "metadata": {
        "id": "KN5sYXoDPVBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# এই লাইনের শুরুতে # দিয়ে কমেন্ট করে দিন, কারণ এটি অলরেডি নামানো আছে\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(token_list):\n",
        "    return [lemmatizer.lemmatize(token) for token in token_list]\n",
        "\n",
        "lemmatized_output = [lemmatize_text(tokens) for tokens in text_without_stopwords]\n",
        "\n",
        "print(lemmatized_output[0][:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkd5561kPhTP",
        "outputId": "75b29798-486f-41c9-deee-f8c825b2036b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Print', 'They', 'pay', 'back', 'money', 'plus', 'interest', 'The', 'entire', 'family', 'everyone', 'came', 'need', 'deported', 'asap', 'Why', 'take', 'two', 'year', 'bust', 'Here', 'go', 'another', 'group', 'stealing', 'government', 'taxpayer', 'A', 'group', 'Somalis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK:9:Synonym Substitution"
      ],
      "metadata": {
        "id": "6_al5LqVSirP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# ১. ছবির মেথড অনুযায়ী ফাংশন তৈরি\n",
        "def synonym_substitution(tokens_list):\n",
        "    new_sentence = []\n",
        "\n",
        "    for word in tokens_list:\n",
        "        synonyms = wordnet.synsets(word)\n",
        "\n",
        "        # যদি শব্দটির কোনো সিনোনিম বা সমার্থক শব্দ ডিকশনারিতে পাওয়া যায়\n",
        "        if synonyms:\n",
        "            # প্রথম সিনোনিমটি খুঁজে বের করা (এটিই হবে আমাদের replacement_word)\n",
        "            new_word = synonyms[0].lemmas()[0].name()\n",
        "\n",
        "            # যদি সিনোনিমটি মূল শব্দের চেয়ে আলাদা হয় এবং এতে কোনো আন্ডারস্কোর (_) না থাকে\n",
        "            if new_word != word and \"_\" not in new_word:\n",
        "                new_sentence.append(new_word) # রিপ্লেস করা হলো\n",
        "            else:\n",
        "                new_sentence.append(word)     # আগেরটাই রাখা হলো\n",
        "        else:\n",
        "            new_sentence.append(word)         # সিনোনিম না পেলে যা ছিল তাই থাকবে\n",
        "\n",
        "    return new_sentence\n",
        "\n",
        "# ২. আপনার লেমাটাইজড ডাটার ওপর এটি চালানো\n",
        "# 'lemmatized_output' হলো আপনার আগের ধাপের ডাটা\n",
        "synonym_replaced_data = [synonym_substitution(tokens) for tokens in lemmatized_output]\n",
        "\n",
        "# ৩. আউটপুট দেখা\n",
        "print(synonym_replaced_data[0][:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgb3wEe4SnQ1",
        "outputId": "874009ec-cbde-4b7a-a799-96bc072ec14f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['print', 'They', 'wage', 'back', 'money', 'asset', 'interest', 'The', 'stallion', 'family', 'everyone', 'come', 'need', 'behave', 'ASAP', 'why', 'return', 'two', 'year', 'flop', 'here', 'go', 'another', 'group', 'larceny', 'government', 'taxpayer', 'angstrom', 'group', 'Somalian']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK:10:Split (Train , Test/Validation)"
      ],
      "metadata": {
        "id": "-oveGPczViMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ১. টোকেনগুলোকে জোড়া লাগিয়ে আবার বাক্যে রূপান্তর করা\n",
        "# 'synonym_replaced_data' হলো আপনার সর্বশেষ প্রসেস করা ডেটা\n",
        "X_text = [\" \".join(tokens) for tokens in synonym_replaced_data]\n",
        "\n",
        "# ২. ফিচার এবং লেবেল ঠিক করা\n",
        "X = X_text\n",
        "y = df['type']\n",
        "\n",
        "# ৩. Train-Test Split (৮০% ট্রেনিং, ২০% টেস্টিং)\n",
        "# test_size=0.2 মানে ২০% ডেটা পরীক্ষার জন্য\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ৪. রেজাল্ট দেখা\n",
        "print(\"Total Data:\", len(X))\n",
        "print(\"Training Data Size (80%):\", len(X_train))\n",
        "print(\"Testing Data Size (20%):\", len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYCpzABpybRb",
        "outputId": "c46f9948-7aef-4ab1-f386-d11fcbeaa392"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Data: 10000\n",
            "Training Data Size (80%): 8000\n",
            "Testing Data Size (20%): 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK:11:Using TF-IDF"
      ],
      "metadata": {
        "id": "PYWynl7u5Ifj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# ১. min_df=5 : যে শব্দটি অন্তত ৫টি আলাদা নিউজে আসেনি, সেটি বাদ যাবে (Typo বা ফালতু শব্দ কমে যাবে)\n",
        "# ২. ngram_range=(1, 3) : এখনো ১-৩ শব্দের জোড়া রাখা হলো যাতে কনটেক্সট থাকে\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=5)\n",
        "\n",
        "# ৩. Training Data-র ওপর fit এবং transform করা\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# ৪. Testing Data-র ওপর transform করা\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# ৫. আউটপুট চেক করা\n",
        "print(\"Training Data Shape:\", X_train_tfidf.shape)\n",
        "print(\"Testing Data Shape:\", X_test_tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nlOFREU5NLl",
        "outputId": "fa0f7002-0768-411d-fcdc-8e4383db226e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Shape: (8000, 129206)\n",
            "Testing Data Shape: (2000, 129206)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK:12:Applying Naïve Bayes Algorithm"
      ],
      "metadata": {
        "id": "99oxZGfYWn5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# ১. মডেল তৈরি করা\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# ২. ট্রেনিং ডেটা দিয়ে মডেল ট্রেইন করা\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# ৩. টেস্ট ডেটা দিয়ে প্রেডিকশন করা\n",
        "y_pred = nb_model.predict(X_test_tfidf)\n",
        "\n",
        "# ৪. আউটপুট (আপনার চাওয়া অনুযায়ী শুধু মেসেজ)\n",
        "print(\"Naive Bayes algorithm has been applied successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGS2FjmxWyjq",
        "outputId": "bbdec606-40da-456d-f5ac-b59062fc5bef"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes algorithm has been applied successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK:13:Confusion matrix & Curve (ROC, AUC)"
      ],
      "metadata": {
        "id": "lXWSadl2Yw61"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EYdxfVDQY4ir"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}